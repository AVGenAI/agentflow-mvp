# Multi-Model Configuration for AgentFlow
# Each agent uses its optimized model

# Primary LLM Provider
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434

# Global fallback model (if agent-specific not available)
OLLAMA_MODEL=qwen2.5:7b

# Agent-Specific Model Overrides (Optional)
# Uncomment to override the default model for specific agents

# Document & Data Processing Agents
# DOCUMENT_INTELLIGENCE_MODEL=qwen2.5:14b
# DATA_ANALYST_MODEL=qwen2.5:14b
# FINANCIAL_ANALYST_MODEL=qwen2.5:14b

# Customer-Facing Agents
# CUSTOMER_SERVICE_MODEL=llama3.1:8b
# HR_RECRUITMENT_MODEL=llama3.1:8b

# Compliance & Quality Agents
# COMPLIANCE_OFFICER_MODEL=qwen2.5:7b
# QUALITY_ASSURANCE_MODEL=gemma2:9b

# Process & Decision Agents
# PROCESS_AUTOMATION_MODEL=mistral:7b
# DECISION_MAKING_MODEL=qwen2.5:14b

# Model Parameters (Global)
OLLAMA_TEMPERATURE=0.5
OLLAMA_MAX_TOKENS=4096
OLLAMA_CONTEXT_LENGTH=32768

# Performance Settings
OLLAMA_NUM_PARALLEL=2  # Number of parallel requests
OLLAMA_NUM_GPU=1       # Number of GPUs to use